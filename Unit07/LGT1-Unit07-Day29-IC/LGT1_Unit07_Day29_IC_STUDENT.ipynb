{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c546c9-b531-4b49-9f09-4f84e0b746a9",
   "metadata": {},
   "source": [
    "# LGT1 Unit07 Day29 - In-Class Assignment:  ML for the Inverse Problem in the Pseudo-PDF Method for LQCD\n",
    "### <p style=\"text-align: right;\"> &#9989; Put your name here.</p>\n",
    "#### <p style=\"text-align: right;\"> &#9989; Put your group member names here.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8038f13-ffd8-4e92-b455-7b63eebb3481",
   "metadata": {},
   "source": [
    "## Goals of this assignment\n",
    "\n",
    "The goals of this assignment are:\n",
    "\n",
    "* Construct and train a multi-layer perceptron (MLP) to produce PDFs from lattice (pseudo-)data\n",
    "* Tune the hyperparameters of the MLP to get the best validation accuracy\n",
    "* See how well the model can predict pseudo-data generated from more complicated functions\n",
    "\n",
    "## Assignment instructions\n",
    "\n",
    "Work with your group to complete this assignment. Upload the assignment to Gradescope at the end of class.\n",
    "**Make sure everyone's name is listed in everyone's notebook before moving on**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec8ecb-b69c-4772-84b2-ea0fc3c45b05",
   "metadata": {},
   "source": [
    "# Part 1: Train and Tune a MLP Regressor\n",
    "In this section, we will load in the pseudo-data and create a multilayer perceptron (MLP) model with SciKit Learn to predict the PDF.\n",
    "The input and output pseudo-data will be exactly the same format as we generated in the pre-class assignment (except the input RpITD is flattened instead of 2D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f79aaca-6146-4eba-8498-b7a88de8d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need this to display plots with latex in google colab\n",
    "#!sudo apt install cm-super dvipng texlive-latex-extra texlive-latex-recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e330b006-c0eb-480e-878c-acc1569a9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries and stuff to include\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c539d16-1b1f-4957-8569-173a6af30fed",
   "metadata": {},
   "source": [
    "## Read In and Split the Data\n",
    "We load the trainig input RpITD pseudo-data from \"indata.npy\" and the training output PDFs from \"outdata.npy\". \n",
    "Additionally, I provide the the $(a,b)$ pairs that correspond to the PDFs, so that we can see later how well we reproduce certain types of PDFs.\n",
    "I decided that 2000 samples was a little better for this exercise than the orginally proposed 1000 samples.\n",
    "We do a 67/33 training to testing split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff208c-5e64-43f0-bc76-7fc39d70837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"indata.npy\")\n",
    "y = np.load(\"outdata.npy\")\n",
    "ab_pairs = np.load(\"ab_pairs.npy\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bfed4cb-7918-45d1-9bc5-446bb9994a1a",
   "metadata": {},
   "source": [
    "## Train the Model and Play With Hyperparameters\n",
    "For the first task, we will take the standard SKLearn MPLRegressor, train it, and read out the train and test mean squared error (this is what the standard MLP regressor uses as its loss function).\n",
    "\n",
    "The most important hyperparameter in an MLP is probably ```hidden_layer_sizes```.\n",
    "This determines the overall structure of the MLP.\n",
    "Our MLP will automatically have a input and output sizes of 25 and 99 respectively based on our input and output data.\n",
    "The number of hidden layers and their sizes is up to you!\n",
    "\n",
    "We will also consider the ```activation``` functions. \n",
    "```MLPRegressor``` supports ```{'identity', 'logistic', 'tanh', 'relu'}```.\n",
    "\n",
    "\n",
    "The ```solver``` and learing rate (```alpha```) are worth exploring as well.\n",
    "```MLPRegressor``` supports solvers ```{'lbfgs', 'sgd', 'adam'}```.\n",
    "```lbfgs``` is fairly slow in my experience and doesn't converge, but that doesn't necessarily mean you should avoid it fully. \n",
    "Just keep in mind that there are other exercises to get to.\n",
    "\n",
    "As mentioned in a previous notebook, you have to be careful with ```alpha```, as too large can cause divergence and too small can cause things to slow down. \n",
    "The default ```alpha``` for ```MLPRegressor``` is 0.0001.\n",
    "\n",
    "Finally, if you have time, you can look into more parameters for ```MLPRegressor``` in the SKLearn documenation [here](https://scikit-learn.org/dev/modules/generated/sklearn.neural_network.MLPRegressor.html).\n",
    "\n",
    "### (Task 1): Play with the hyperparameters\n",
    "Modify the code below to see what gets you the smallest mean squared error (MSE).\n",
    "Write observations in the cell below the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640af102-f5c4-4cc0-ba35-830148f661a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main hyperparameters\n",
    "layers = ### YOUR CODE HERE # Should be an n-tuple of integers, ex. (10,10,10) \n",
    "activate = ### YOUR CODE HERE # Choose from {'identity', 'logistic', 'tanh', 'relu'}\n",
    "solve = ### YOUR CODE HERE # Choose from {'lbfgs', 'sgd', 'adam'}\n",
    "learn_rate = 0.00001 # Learning rate, you may change this, if you want\n",
    "\n",
    "\n",
    "\n",
    "# Create the MLPRegressor\n",
    "mlp_test=MLPRegressor(hidden_layer_sizes=layers, activation = activate, solver = solve, alpha = learn_rate, random_state = 0, max_iter=2000)\n",
    "\n",
    "#Train on the test set\n",
    "mlp_test.fit(X_train, y_train)\n",
    "\n",
    "#calculate and read out the test and train error\n",
    "train_mse = metrics.mean_squared_error(mlp_test.predict(X_train), y_train)\n",
    "test_mse = metrics.mean_squared_error(mlp_test.predict(X_test), y_test)\n",
    "\n",
    "print(\"Train error:\", train_mse)\n",
    "print(\"Test error:\", test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5a808-41aa-4bed-ba52-377a6b4bdc4d",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "Write take some notes about your findings in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a0ae5-2b31-4679-95c3-3c38dc3f1a14",
   "metadata": {},
   "source": [
    "\\[Your notes here\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a20ba-ce77-4e81-846e-481de3f1c586",
   "metadata": {},
   "source": [
    "### (Task 2): Visualize the Results\n",
    "The MSE can only really tell us so much about your results from the MSE, so pick some samples, plotting the actual and predicted results.\n",
    "Make comments in the markdown cells below the code block.\n",
    "\n",
    "Reminder: Samples 0-1339 are the training samples, and 1340-1999 are the test samples. Make sure to make some observations about samples from both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a489c-439a-47ed-b876-bd487bf6c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ### YOUR CODE HERE # Sample to plot\n",
    "\n",
    "#print (a,b) of the sample\n",
    "ab = ab_pairs[sample]\n",
    "print(\"a =\", ab[0], \"b =\", ab[1])\n",
    "\n",
    "#Get actual and predicted gluon PDFs\n",
    "xgx = y[sample] #actual\n",
    "xgx_pred = mlp_test.predict([X[sample]]) #predicted\n",
    "\n",
    "#Make an array of the x values for the PDFs\n",
    "xs_out = np.arange(1, 100)/100\n",
    "\n",
    "#Plot of the output PDF data\n",
    "plt.plot(xs_out, xgx, label = \"actual\")\n",
    "plt.plot(xs_out, xgx_pred[0], label = \"predicted\")\n",
    "plt.xlabel(r'$x$', fontsize = 18)\n",
    "plt.ylabel(r'$xg(x)/\\langle x_g \\rangle$', fontsize = 18)\n",
    "#plt.yscale('log') ### You can uncomment this to look a little closer at the large-x region\n",
    "plt.legend(fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c78247-7449-40fe-b71e-d667b0aa7aff",
   "metadata": {},
   "source": [
    "### Record your observations\n",
    "\\[Your notes here\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f712a-33b5-43c5-892a-30084365b32f",
   "metadata": {},
   "source": [
    "# Part 2: Compare to a \"Realistic\" PDF (30 minutes?)\n",
    "We have seen that our model can somewhat reasonably reproduce simple model PDFs from their pseudo-RpITD-data, but what if actual lattice predicts a more complicated PDF?\n",
    "Can our model handle it?\n",
    "\n",
    "\n",
    "I have taken the more complicated parameterization of the gluon PDF from the CT18 global fit ([arXiv:1912.10053v3](https://arxiv.org/abs/1912.10053)) and generated PDFs and corresponding pseudo-data with 5% variance around their parameters.\n",
    "We would like to see if our model can reproduce the more complicated PDF forms.\n",
    "\n",
    "## Read in The Challenge Data\n",
    "We have 1000 samples of the challenge input and output data.\n",
    "We are NOT training our model with this data, just testing it, so there are no test-train splits.\n",
    "The ```indata_challenge.npy``` and ```outdata_challenge.npy``` sets are organized exactly like the training data.\n",
    "```PDF_challenge_mean_err.npy``` and ```RpITD_challenge_mean_err.npy``` contain the mean and error for the PDFs and the RpITDs for later plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc399c-eee1-497b-9731-133d4911fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_challenge = np.load(\"indata_challenge.npy\")\n",
    "y_challenge = np.load(\"outdata_challenge.npy\")\n",
    "\n",
    "PDF_challenge = np.load(\"PDF_challenge_mean_error.npy\")\n",
    "RpITD_challenge = np.load(\"RpITD_challenge_mean_error.npy\")\n",
    "\n",
    "N_data = len(y_challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8bab6-979f-42f6-a641-1f46c97fd355",
   "metadata": {},
   "source": [
    "### (Task 3): PDF Visualization\n",
    "Below, we plot the random sample of PDFs that I generated from the more complicated parameterization.\n",
    "In the cell below the plot, comment any observations you see compared to the behavior of our simpler model PDFs.\n",
    "Do you think our model will be able to handle the features of these PDFs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ae6dc-ba0d-4347-b55d-a50a2fff9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_out = np.arange(1,100)/100 \n",
    "\n",
    "for i in range(N_data):\n",
    "    plt.plot(xs_out, y_challenge[i], color = 'tab:blue', alpha = .2)\n",
    "\n",
    "plt.xlabel(r'$x$', fontsize = 18)\n",
    "plt.ylabel(r'$xg(x)/\\langle x_g \\rangle$', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9834b5-d2d1-45b7-b397-fa93895a17ae",
   "metadata": {},
   "source": [
    "\\[Your comments here\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484eb6b-18b2-4a6c-ba9a-c464c0739b9d",
   "metadata": {},
   "source": [
    "### (Task 4): Use Your Best Model to Predict the PDFs\n",
    "Ensure that the last time you trained ```mlp_test``` that you trained with the best hyperparameters.\n",
    "Run the cell below to predict the challenge PDFs with your model.\n",
    "Comment in the markdown cell below how your model does on these PDFs compared to the train and test sets.\n",
    "\n",
    "Do NOT go back and retrain your model. We'll build a new model in a couple more tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07eea91-8611-4971-a1d6-2f2f3c347bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate and read out the test and train error\n",
    "train_mse = metrics.mean_squared_error(mlp_test.predict(X_train), y_train)\n",
    "test_mse = metrics.mean_squared_error(mlp_test.predict(X_test), y_test)\n",
    "challenge_mse = metrics.mean_squared_error(mlp_test.predict(X_challenge), y_challenge)\n",
    "\n",
    "print(\"Train error:\", train_mse)\n",
    "print(\"Test error:\", test_mse)\n",
    "print(\"Challenge error:\", challenge_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55694c3f-5a16-4914-a2a9-fd1f7de1057f",
   "metadata": {},
   "source": [
    "\\[Your comments here\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c96a3-3aaf-43d0-b692-4de563c46b8a",
   "metadata": {},
   "source": [
    "### (Task 5): What's going wrong (or Right)?\n",
    "Choose some challenge PDF samples and compare your actual and predicted PDFs.\n",
    "Comment in the markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d668f277-6781-4fee-a118-c4e1a9a1bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ### YOUR CODE HERE # Sample to plot\n",
    "\n",
    "#Get actual and predicted gluon PDFs\n",
    "xgx = y_challenge[sample] #actual\n",
    "xgx_pred = mlp_test.predict([X_challenge[sample]]) #predicted\n",
    "\n",
    "#Make an array of the x values for the PDFs\n",
    "xs_out = np.arange(1, 100)/100\n",
    "\n",
    "#Plot of the output PDF data\n",
    "plt.plot(xs_out, xgx, label = \"actual\")\n",
    "plt.plot(xs_out, xgx_pred[0], label = \"predicted\")\n",
    "plt.xlabel(r'$x$', fontsize = 18)\n",
    "plt.ylabel(r'$xg(x)/\\langle x_g \\rangle$', fontsize = 18)\n",
    "#plt.yscale('log') ### You can uncomment this to look a little closer at the large-x region\n",
    "plt.legend(fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5567b3-9dbb-4872-8993-9f8417b46007",
   "metadata": {},
   "source": [
    "\\[Your comments here\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e507ea-04e8-4e9a-8c2e-75b6f3cc38ec",
   "metadata": {},
   "source": [
    "### (Task 6): How Well Can We Predict Complicated Data from Simple Pseudo-Data?\n",
    "In this task, we will train a new model on the original simple pseuod-data, but we will try to optimize the parameters to predict the more complicated PDFs.\n",
    "This should be similar to task 1.\n",
    "Comment your observations in the markdown cell below.\n",
    "How well can we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67280ef-f4d5-41c0-820e-11abddfdf981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main hyperparameters\n",
    "layers = ### YOUR CODE HERE # Should be an n-tuple of integers, ex. (10,10,10) \n",
    "activate = ### YOUR CODE HERE # Choose from {'identity', 'logistic', 'tanh', 'relu'}\n",
    "solve = ### YOUR CODE HERE # Choose from {'lbfgs', 'sgd', 'adam'}\n",
    "learn_rate = 0.0001 # Learning rate, you may change this, if you want\n",
    "\n",
    "\n",
    "\n",
    "# Create the MLPRegressor\n",
    "mlp_new=MLPRegressor(hidden_layer_sizes=layers, activation = activate, solver = solve, alpha = learn_rate, random_state = 0, max_iter=2000)\n",
    "\n",
    "#Train on the test set\n",
    "mlp_new.fit(X_train, y_train)\n",
    "\n",
    "#calculate and read out the test and train error\n",
    "train_mse = metrics.mean_squared_error(mlp_new.predict(X_train), y_train)\n",
    "test_mse = metrics.mean_squared_error(mlp_new.predict(X_test), y_test)\n",
    "challenge_mse = metrics.mean_squared_error(mlp_new.predict(X_challenge), y_challenge)\n",
    "\n",
    "print(\"Train error:\", train_mse)\n",
    "print(\"Test error:\", test_mse)\n",
    "print(\"Challenge error:\", challenge_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292c53f5-b11d-4dc7-86a6-4f8446d6a138",
   "metadata": {},
   "source": [
    "\\[Your comments here\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4da24a-0d85-4019-ae5d-dd6d30b394cf",
   "metadata": {},
   "source": [
    "### (Task 7): Comment on the PDFs Again\n",
    "Again, plot some PDF samples from your newly optimized model and compare to the actual results.\n",
    "Is there distinctive features that our model can't seem to reproduce?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad8f68b-2c82-476e-b3b0-9c89207b7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ### YOUR CODE HERE # Sample to plot\n",
    "\n",
    "#Get actual and predicted gluon PDFs\n",
    "xgx = y_challenge[sample] #actual\n",
    "xgx_pred = mlp_new.predict([X_challenge[sample]]) #predicted\n",
    "\n",
    "#Make an array of the x values for the PDFs\n",
    "xs_out = np.arange(1, 100)/100\n",
    "\n",
    "#Plot of the output PDF data\n",
    "plt.plot(xs_out, xgx, label = \"actual\")\n",
    "plt.plot(xs_out, xgx_pred[0], label = \"predicted\")\n",
    "plt.xlabel(r'$x$', fontsize = 18)\n",
    "plt.ylabel(r'$xg(x)/\\langle x_g \\rangle$', fontsize = 18)\n",
    "#plt.yscale('log') ### You can uncomment this to look a little closer at the large-x region\n",
    "plt.legend(fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e67a5e-6598-4ba8-817a-c8e057b90de8",
   "metadata": {},
   "source": [
    "\\[Your comments here\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff1a18-ed1a-4cba-819b-608b305265fa",
   "metadata": {},
   "source": [
    "### (Task 8): Mean and Error\n",
    "We're dealing with statistics here, so let's take a look at the mean and error of the actual vs predicted PDFs to be able to make some more general comments.\n",
    "We'll make two different plots. \n",
    "Add your observations to the cell at the end of this section.\n",
    "\n",
    "The first plot is just the mean and the error of the two PDF sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b33b5-76a9-4485-94bd-f43a3e5931d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PDF_challenge[:,0],PDF_challenge[:,1], color = 'tab:blue', label = \"actual\")\n",
    "plt.fill_between(PDF_challenge[:,0], PDF_challenge[:,1] + PDF_challenge[:,2],\n",
    "                PDF_challenge[:,1] - PDF_challenge[:,2], color = 'tab:blue', alpha=0.2)\n",
    "\n",
    "\n",
    "#Get the mean the the error of the predicted PDFs\n",
    "y_preds = mlp_new.predict(X_challenge)\n",
    "\n",
    "y_pred_mean = np.mean(y_preds, axis = 0)\n",
    "y_pred_error = np.std(y_preds, axis = 0)\n",
    "\n",
    "plt.plot(PDF_challenge[:,0], y_pred_mean, color = 'tab:orange', label = \"predicted\")\n",
    "plt.fill_between(PDF_challenge[:,0], y_pred_mean + y_pred_error,\n",
    "                 y_pred_mean - y_pred_error, color = 'tab:orange', alpha=0.2)\n",
    "\n",
    "plt.xlabel(r'$x$', fontsize = 18)\n",
    "plt.ylabel(r'$xg(x)/\\langle x_g \\rangle$', fontsize = 18)\n",
    "#plt.yscale('log') ### You can uncomment this to look a little closer at the large-x region\n",
    "plt.legend(fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61385280-1970-465a-a070-029b4a7eaf5f",
   "metadata": {},
   "source": [
    "Below is a common plot for PDF visualization, where the PDFs and the errors are divided by the mean PDF from one global fit.\n",
    "This allows us to see relative errors better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ebe1d-957a-4aaf-9d57-a6506fdab024",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PDF_challenge[:,0],PDF_challenge[:,1]/PDF_challenge[:,1], color = 'tab:blue', label = \"actual\")\n",
    "plt.fill_between(PDF_challenge[:,0], (PDF_challenge[:,1] + PDF_challenge[:,2])/PDF_challenge[:,1],\n",
    "                (PDF_challenge[:,1] - PDF_challenge[:,2])/PDF_challenge[:,1], color = 'tab:blue', alpha=0.2)\n",
    "\n",
    "\n",
    "#Get the mean the the error of the predicted PDFs\n",
    "y_preds = mlp_new.predict(X_challenge)\n",
    "\n",
    "y_pred_mean = np.mean(y_preds, axis = 0)\n",
    "y_pred_error = np.std(y_preds, axis = 0)\n",
    "\n",
    "plt.plot(PDF_challenge[:,0], y_pred_mean/PDF_challenge[:,1], color = 'tab:orange', label = \"predicted\")\n",
    "plt.fill_between(PDF_challenge[:,0], (y_pred_mean + y_pred_error)/PDF_challenge[:,1],\n",
    "                 (y_pred_mean - y_pred_error)/PDF_challenge[:,1], color = 'tab:orange', alpha=0.2)\n",
    "\n",
    "plt.xlabel(r'$x$', fontsize = 18)\n",
    "plt.ylabel(r'$g(x)/g^{actual}(x) \\rangle$', fontsize = 18)\n",
    "plt.ylim(0,2)\n",
    "#plt.yscale('log') ### You can uncomment this to look a little closer at the large-x region\n",
    "plt.legend(fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a1671c-91f4-4869-8e8e-f351ad2b88fc",
   "metadata": {},
   "source": [
    "\\[Your comments here\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3662e640-c96d-43c1-8daa-3cd379dded17",
   "metadata": {},
   "source": [
    "# Part 3: Discussion\n",
    "Overall, we have implemented a very simple model with simple pseudo-data.\n",
    "Take a few minutes to discuss what you think may be problems with the ways we have implemented everything and how we could resolve them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e77dd5-1495-4c3d-96ec-97490f4c990f",
   "metadata": {},
   "source": [
    "\\[Your comments here\\]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
